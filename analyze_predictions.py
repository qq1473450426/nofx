#!/usr/bin/env python3
"""åˆ†ææœ€è¿‘90ä¸ªå‘¨æœŸçš„AIé¢„æµ‹è¡Œä¸º"""
import json
import glob
import re
from collections import Counter, defaultdict

# è·å–æ‰€æœ‰decision logs
files = sorted(glob.glob('decision_logs/binance_live_qwen/*.json'))

predictions = []
directions = []
probabilities = []
symbols_analysis = defaultdict(lambda: {'neutral': 0, 'up': 0, 'down': 0, 'total': 0})
reasoning_keywords = Counter()
high_prob_predictions = []  # é«˜æ¦‚ç‡ä½†æœªå¼€ä»“çš„

# æ­£åˆ™è¡¨è¾¾å¼æå–é¢„æµ‹æ•°æ®
pattern = r'\*\*([A-Z]+USDT)é¢„æµ‹\*\*:\s+æ–¹å‘: (\w+) \| æ¦‚ç‡: (\d+)% \| é¢„æœŸå¹…åº¦: ([+-]?\d+\.\d+)% \| æ—¶é—´: (\w+)\s+ç½®ä¿¡åº¦: (\w+) \| é£é™©: (\w+) \| æœ€å¥½: ([+-]?\d+\.\d+)% \| æœ€å: ([+-]?\d+\.\d+)%\s+æ¨ç†: (.+?)\n'

for file_path in files:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        cot_trace = data.get('cot_trace', '')
        cycle = data.get('cycle_number', 0)

        # ä½¿ç”¨æ­£åˆ™æå–æ‰€æœ‰é¢„æµ‹
        matches = re.findall(pattern, cot_trace, re.MULTILINE)

        for match in matches:
            symbol = match[0]
            direction = match[1]
            probability = int(match[2]) / 100.0  # è½¬æ¢ä¸º0-1
            expected_move = float(match[3])
            timeframe = match[4]
            confidence = match[5]
            risk = match[6]
            best_case = float(match[7])
            worst_case = float(match[8])
            reasoning = match[9].strip()

            predictions.append({
                'cycle': cycle,
                'symbol': symbol,
                'direction': direction,
                'probability': probability,
                'reasoning': reasoning,
                'confidence': confidence,
            })

            directions.append(direction)
            probabilities.append(probability)
            symbols_analysis[symbol][direction] += 1
            symbols_analysis[symbol]['total'] += 1

            # æå–reasoningå…³é”®è¯
            keywords = ['é‡ä»·èƒŒç¦»', 'æƒ…ç»ªèƒŒç¦»', 'æŒ‡æ ‡å†²çª', 'æˆäº¤é‡ä¸‹é™', 'å¸‚åœºæƒ…ç»ªæ‚²è§‚',
                       'æµåŠ¨æ€§ä¸è¶³', 'è¶‹åŠ¿', 'RSIè¶…ä¹°', 'RSIè¶…å–', 'éœ‡è¡', 'äº¤æ˜“é‡ä½',
                       'çŸ­æœŸè¶‹åŠ¿å¼±', 'é•¿æœŸå‡çº¿æä¾›æ”¯æ’‘', 'MACD', 'ç¼ºä¹', 'ä¸è¶³']
            for kw in keywords:
                if kw in reasoning:
                    reasoning_keywords[kw] += 1

            # è®°å½•é«˜æ¦‚ç‡é¢„æµ‹
            if direction in ['up', 'down'] and probability >= 0.65:
                high_prob_predictions.append({
                    'cycle': cycle,
                    'symbol': symbol,
                    'direction': direction,
                    'probability': probability,
                    'reasoning': reasoning[:100]
                })
    except Exception as e:
        print(f"Error reading {file_path}: {e}")

# ç»Ÿè®¡åˆ†æ
print("=" * 80)
print(f"ğŸ“Š åˆ†æå‘¨æœŸæ•°: {len(files)}")
print(f"ğŸ“Š æ€»é¢„æµ‹æ•°: {len(predictions)}")
print("=" * 80)

print("\n## 1ï¸âƒ£ æ–¹å‘åˆ†å¸ƒ (Direction Distribution)")
direction_count = Counter(directions)
for direction, count in direction_count.most_common():
    pct = count / len(directions) * 100 if directions else 0
    bar = 'â–ˆ' * int(pct / 2)
    print(f"  {direction:8s}: {count:4d} ({pct:5.1f}%) {bar}")

print("\n## 2ï¸âƒ£ æ¦‚ç‡åˆ†å¸ƒ (Probability Distribution)")
prob_ranges = {
    '0.50-0.55': 0,
    '0.55-0.60': 0,
    '0.60-0.65': 0,
    '0.65-0.70': 0,
    '0.70-0.75': 0,
    '0.75-0.80': 0,
    '0.80-1.00': 0,
}
for p in probabilities:
    if 0.50 <= p < 0.55:
        prob_ranges['0.50-0.55'] += 1
    elif 0.55 <= p < 0.60:
        prob_ranges['0.55-0.60'] += 1
    elif 0.60 <= p < 0.65:
        prob_ranges['0.60-0.65'] += 1
    elif 0.65 <= p < 0.70:
        prob_ranges['0.65-0.70'] += 1
    elif 0.70 <= p < 0.75:
        prob_ranges['0.70-0.75'] += 1
    elif 0.75 <= p < 0.80:
        prob_ranges['0.75-0.80'] += 1
    elif p >= 0.80:
        prob_ranges['0.80-1.00'] += 1

for range_name, count in prob_ranges.items():
    pct = count / len(probabilities) * 100 if probabilities else 0
    bar = 'â–ˆ' * int(pct / 2)
    print(f"  {range_name}: {count:4d} ({pct:5.1f}%) {bar}")

print("\n## 3ï¸âƒ£ å„å¸ç§é¢„æµ‹åˆ†å¸ƒ")
for symbol, stats in sorted(symbols_analysis.items()):
    total = stats['total']
    neutral_pct = stats['neutral'] / total * 100 if total > 0 else 0
    up_pct = stats['up'] / total * 100 if total > 0 else 0
    down_pct = stats['down'] / total * 100 if total > 0 else 0
    print(f"  {symbol:10s}: neutral={neutral_pct:5.1f}% | up={up_pct:5.1f}% | down={down_pct:5.1f}% (n={total})")

print("\n## 4ï¸âƒ£ Reasoningå…³é”®è¯TOP 15")
for kw, count in reasoning_keywords.most_common(15):
    pct = count / len(predictions) * 100 if predictions else 0
    print(f"  {kw:20s}: {count:4d} ({pct:5.1f}%)")

print("\n## 5ï¸âƒ£ é«˜æ¦‚ç‡é¢„æµ‹ (â‰¥0.65 ä¸” direction=up/down)")
print(f"  æ€»æ•°: {len(high_prob_predictions)}")
if high_prob_predictions:
    print("\n  è¯¦ç»†åˆ—è¡¨:")
    for pred in high_prob_predictions[:30]:  # æ˜¾ç¤ºå‰30ä¸ª
        print(f"    Cycle {pred['cycle']:3d} | {pred['symbol']:8s} | {pred['direction']:5s} | P={pred['probability']:.2f}")
        print(f"      â†’ {pred['reasoning']}")

print("\n## 6ï¸âƒ£ è¯Šæ–­ç»“è®º")
neutral_pct = direction_count.get('neutral', 0) / len(directions) * 100 if directions else 0
up_down_pct = 100 - neutral_pct

if neutral_pct > 98:
    print("  ğŸš¨ ä¸¥é‡é—®é¢˜: AIå‡ ä¹åªè¾“å‡ºneutral (>98%)")
    print("  â†’ å¯èƒ½åŸå› :")
    print("    1. æ¦‚ç‡æ ¡å‡†è¿‡äºä¿å®ˆ")
    print("    2. å…³é”®å†²çªæ£€æµ‹è¿‡äºä¸¥æ ¼")
    print("    3. Promptå¯¼è‡´AIä¸æ•¢åšå‡ºé¢„æµ‹")
    print("  â†’ å»ºè®®:")
    print("    1. æ£€æŸ¥æ˜¯å¦æœ‰éšå«çš„å¿ƒç†é”šå®š")
    print("    2. é™ä½å…³é”®å†²çªçš„è§¦å‘é˜ˆå€¼")
    print("    3. ç»™AIæ›´å¤šencouragementå»åšå‡ºé¢„æµ‹")
elif neutral_pct > 90:
    print("  âš ï¸  é—®é¢˜: AIè¿‡äºä¿å®ˆ (90-98% neutral)")
    print("  â†’ å¸‚åœºå¯èƒ½ç¡®å®ä¸ç¡®å®šï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯Promptè¿‡äºä¸¥æ ¼")
    print("  â†’ å»ºè®®: è§‚å¯Ÿreasoningä¸­çš„é«˜é¢‘å…³é”®è¯ï¼Œçœ‹æ˜¯å¦æœ‰ç³»ç»Ÿæ€§é—®é¢˜")
elif neutral_pct > 70:
    print("  âœ… åŸºæœ¬æ­£å¸¸: AIå€¾å‘äºè§‚æœ› (70-90% neutral)")
    print("  â†’ è¿™æ˜¯V6.0çš„é¢„æœŸè¡Œä¸ºï¼ˆä¿å®ˆçš„æ¨¡å¼è¯†åˆ«è€…ï¼‰")
    print("  â†’ å¦‚æœå¸‚åœºç¡®å®ä¸ç¡®å®šï¼Œè¿™æ˜¯æ­£ç¡®çš„")
elif len(high_prob_predictions) > 20:
    print("  âš ï¸  é—®é¢˜: æœ‰å¤šä¸ªé«˜æ¦‚ç‡é¢„æµ‹ä½†æœªå¼€ä»“")
    print("  â†’ éœ€è¦æ£€æŸ¥:")
    print("    1. RiskAgentçš„éªŒè¯é€»è¾‘")
    print("    2. ç¡¬çº¦æŸæ¡ä»¶æ˜¯å¦è¿‡ä¸¥")
    print("    3. å¼ºå¹³ä»·æ ¡éªŒæ˜¯å¦å¤±æ•ˆ")
else:
    print("  âœ… æ­£å¸¸: AIè¡¨ç°ç¬¦åˆå¸‚åœºæ¡ä»¶")
    print(f"  â†’ Up/Downé¢„æµ‹å æ¯”: {up_down_pct:.1f}%")

# é¢å¤–è¯Šæ–­ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¦‚ç‡éƒ½åœ¨ä¸€ä¸ªå¾ˆçª„çš„èŒƒå›´
if probabilities:
    avg_prob = sum(probabilities) / len(probabilities)
    prob_variance = sum((p - avg_prob) ** 2 for p in probabilities) / len(probabilities)
    prob_std = prob_variance ** 0.5

    print(f"\n## 7ï¸âƒ£ æ¦‚ç‡ç»Ÿè®¡")
    print(f"  å¹³å‡æ¦‚ç‡: {avg_prob:.3f}")
    print(f"  æ ‡å‡†å·®: {prob_std:.3f}")
    print(f"  æœ€å°å€¼: {min(probabilities):.3f}")
    print(f"  æœ€å¤§å€¼: {max(probabilities):.3f}")

    if prob_std < 0.02:
        print("  âš ï¸  æ¦‚ç‡å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼AIå¯èƒ½è¢«é™åˆ¶ä½äº†")
    elif prob_std < 0.05:
        print("  âš ï¸  æ¦‚ç‡å˜åŒ–å¾ˆå°ï¼ŒAIçš„åˆ¤æ–­ç¼ºä¹å¤šæ ·æ€§")

print("\n" + "=" * 80)
